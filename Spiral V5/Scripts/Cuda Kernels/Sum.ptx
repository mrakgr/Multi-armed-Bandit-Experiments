//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21112126
// Cuda compilation tools, release 8.0, V8.0.43
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_30
.address_size 64

	// .globl	Sum
.global .align 1 .b8 _ZN57_INTERNAL_40_tmpxft_00002a3c_00000000_8__temp_cpp1_ii_Sum6thrust6system6detail10sequential3seqE[1];
// Sum$__cuda_local_var_537668_58_non_const_temp_storage has been demoted

.visible .entry Sum(
	.param .u32 Sum_param_0,
	.param .u64 Sum_param_1,
	.param .u64 Sum_param_2
)
{
	.reg .pred 	%p<11>;
	.reg .f32 	%f<39>;
	.reg .b32 	%r<40>;
	.reg .b64 	%rd<12>;
	// demoted variable
	.shared .align 4 .b8 Sum$__cuda_local_var_537668_58_non_const_temp_storage[44];

	ld.param.u32 	%r6, [Sum_param_0];
	ld.param.u64 	%rd3, [Sum_param_1];
	ld.param.u64 	%rd2, [Sum_param_2];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	mad.lo.s32 	%r9, %r7, %r8, %r1;
	cvta.to.global.u64 	%rd1, %rd3;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f32 	%f37, [%rd5];
	mov.u32 	%r10, %nctaid.x;
	mul.lo.s32 	%r2, %r10, %r7;
	add.s32 	%r39, %r9, %r2;
	setp.ge.s32	%p1, %r39, %r6;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.wide.s32 	%rd6, %r39, 4;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.f32 	%f8, [%rd7];
	add.f32 	%f37, %f37, %f8;
	add.s32 	%r39, %r39, %r2;
	setp.lt.s32	%p2, %r39, %r6;
	@%p2 bra 	BB0_1;

BB0_2:
	// inline asm
	mov.u32 %r11, %laneid;
	// inline asm
	// inline asm
	mov.u32 %r12, %laneid;
	// inline asm
	mov.b32 	 %r14, %f37;
	mov.u32 	%r15, 1;
	mov.u32 	%r32, 31;
	// inline asm
	shfl.down.b32 %r13, %r14, %r15, %r32;
	// inline asm
	add.s32 	%r33, %r12, 1;
	setp.lt.s32	%p3, %r33, 32;
	mov.b32 	 %f9, %r13;
	add.f32 	%f10, %f37, %f9;
	selp.f32	%f11, %f10, %f37, %p3;
	mov.b32 	 %r18, %f11;
	mov.u32 	%r19, 2;
	// inline asm
	shfl.down.b32 %r17, %r18, %r19, %r32;
	// inline asm
	add.s32 	%r34, %r12, 2;
	setp.lt.s32	%p4, %r34, 32;
	mov.b32 	 %f12, %r17;
	add.f32 	%f13, %f12, %f11;
	selp.f32	%f14, %f13, %f11, %p4;
	mov.b32 	 %r22, %f14;
	mov.u32 	%r23, 4;
	// inline asm
	shfl.down.b32 %r21, %r22, %r23, %r32;
	// inline asm
	add.s32 	%r35, %r12, 4;
	setp.lt.s32	%p5, %r35, 32;
	mov.b32 	 %f15, %r21;
	add.f32 	%f16, %f15, %f14;
	selp.f32	%f17, %f16, %f14, %p5;
	mov.b32 	 %r26, %f17;
	mov.u32 	%r27, 8;
	// inline asm
	shfl.down.b32 %r25, %r26, %r27, %r32;
	// inline asm
	add.s32 	%r36, %r12, 8;
	setp.lt.s32	%p6, %r36, 32;
	mov.b32 	 %f18, %r25;
	add.f32 	%f19, %f18, %f17;
	selp.f32	%f20, %f19, %f17, %p6;
	mov.b32 	 %r30, %f20;
	mov.u32 	%r31, 16;
	// inline asm
	shfl.down.b32 %r29, %r30, %r31, %r32;
	// inline asm
	add.s32 	%r37, %r12, 16;
	setp.lt.s32	%p7, %r37, 32;
	mov.b32 	 %f21, %r29;
	add.f32 	%f22, %f21, %f20;
	selp.f32	%f38, %f22, %f20, %p7;
	setp.ne.s32	%p8, %r11, 0;
	@%p8 bra 	BB0_4;

	shr.u32 	%r38, %r1, 5;
	mul.wide.u32 	%rd8, %r38, 4;
	mov.u64 	%rd9, Sum$__cuda_local_var_537668_58_non_const_temp_storage;
	add.s64 	%rd10, %rd9, %rd8;
	st.shared.f32 	[%rd10+8], %f38;

BB0_4:
	bar.sync 	0;
	setp.ne.s32	%p9, %r1, 0;
	@%p9 bra 	BB0_6;

	ld.shared.f32 	%f23, [Sum$__cuda_local_var_537668_58_non_const_temp_storage+12];
	add.f32 	%f24, %f38, %f23;
	ld.shared.f32 	%f25, [Sum$__cuda_local_var_537668_58_non_const_temp_storage+16];
	add.f32 	%f26, %f25, %f24;
	ld.shared.f32 	%f27, [Sum$__cuda_local_var_537668_58_non_const_temp_storage+20];
	add.f32 	%f28, %f27, %f26;
	ld.shared.f32 	%f29, [Sum$__cuda_local_var_537668_58_non_const_temp_storage+24];
	add.f32 	%f30, %f29, %f28;
	ld.shared.f32 	%f31, [Sum$__cuda_local_var_537668_58_non_const_temp_storage+28];
	add.f32 	%f32, %f31, %f30;
	ld.shared.f32 	%f33, [Sum$__cuda_local_var_537668_58_non_const_temp_storage+32];
	add.f32 	%f34, %f33, %f32;
	ld.shared.f32 	%f35, [Sum$__cuda_local_var_537668_58_non_const_temp_storage+36];
	add.f32 	%f38, %f35, %f34;

BB0_6:
	@%p9 bra 	BB0_8;

	cvta.to.global.u64 	%rd11, %rd2;
	atom.global.add.f32 	%f36, [%rd11], %f38;

BB0_8:
	ret;
}

	// .globl	_ZN3cub11EmptyKernelIvEEvv
.visible .entry _ZN3cub11EmptyKernelIvEEvv(

)
{



	ret;
}


